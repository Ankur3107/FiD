{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FiD Model Inference.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nl18FczM3u4M",
        "outputId": "546297d1-d9d1-4d6f-bbdc-913668424b37"
      },
      "source": [
        "!pip install -q transformers==3.0.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 778kB 6.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 901kB 9.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 19.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0MB 30.1MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q97gWeEF38HS",
        "outputId": "8dbe2bb6-7e86-41d3-97aa-35871a470db9"
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/FiD/pretrained_models/nq_reader_base.tar.gz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-21 14:40:35--  https://dl.fbaipublicfiles.com/FiD/pretrained_models/nq_reader_base.tar.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 825940399 (788M) [application/gzip]\n",
            "Saving to: ‘nq_reader_base.tar.gz’\n",
            "\n",
            "nq_reader_base.tar. 100%[===================>] 787.68M  30.5MB/s    in 25s     \n",
            "\n",
            "2021-04-21 14:41:01 (31.6 MB/s) - ‘nq_reader_base.tar.gz’ saved [825940399/825940399]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNLy57po4CxD"
      },
      "source": [
        "!tar -xf nq_reader_base.tar.gz"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucNcvgkK4Qaw",
        "outputId": "1b3534da-b260-481c-88bf-547879fc68a4"
      },
      "source": [
        "!git clone https://github.com/facebookresearch/FiD.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'FiD'...\n",
            "remote: Enumerating objects: 27, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 27 (delta 4), reused 23 (delta 4), pack-reused 3\u001b[K\n",
            "Unpacking objects: 100% (27/27), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2xaZHjk4gNO",
        "outputId": "7bfecf48-c42f-4303-a387-8c0cfc916f5d"
      },
      "source": [
        "cd FiD"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/FiD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeHgXHPm4itP"
      },
      "source": [
        "import torch\n",
        "import transformers\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import torch.distributed as dist\n",
        "from torch.utils.data import DataLoader, SequentialSampler\n",
        "\n",
        "\n",
        "import src.slurm\n",
        "import src.util\n",
        "from src.options import Options\n",
        "import src.data\n",
        "import src.evaluation\n",
        "import src.model"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpOgATWk4pCb"
      },
      "source": [
        "tokenizer = transformers.T5Tokenizer.from_pretrained('t5-base', return_dict=False)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G-zCTT44x3O"
      },
      "source": [
        "model_class = src.model.FiDT5\n",
        "model = model_class.from_pretrained(\"../nq_reader_base/\")\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMZAyx5b5EUB"
      },
      "source": [
        "example = {\n",
        "    \"question\":'Who is PM of india?',\n",
        "    \"passages\":[\"Narendra Modi PM of india\",\n",
        "                \"I am PM of india\",\n",
        "                \"We are from india\"]\n",
        "}\n",
        "batch = [example]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxplqoHd5xrm"
      },
      "source": [
        "def encode_passages(batch_text_passages, tokenizer, max_length):\n",
        "    passage_ids, passage_masks = [], []\n",
        "    for k, text_passages in enumerate(batch_text_passages):\n",
        "        p = tokenizer.batch_encode_plus(\n",
        "            text_passages,\n",
        "            max_length=max_length,\n",
        "            pad_to_max_length=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        passage_ids.append(p['input_ids'][None])\n",
        "        passage_masks.append(p['attention_mask'][None])\n",
        "\n",
        "    passage_ids = torch.cat(passage_ids, dim=0)\n",
        "    passage_masks = torch.cat(passage_masks, dim=0)\n",
        "    return passage_ids, passage_masks.bool()\n",
        "\n",
        "def append_question(example):\n",
        "    if example['passages'] is None:\n",
        "        return [example['question']]\n",
        "    return [example['question'] + \" \" + t for t in example['passages']]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9yT4iEY58ln"
      },
      "source": [
        "text_passages = [append_question(example) for example in batch]\n",
        "text_maxlength = 128\n",
        "passage_ids, passage_masks = encode_passages(text_passages,\n",
        "                                              tokenizer,\n",
        "                                              text_maxlength)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_fxmMO86OU3"
      },
      "source": [
        "outputs = model.generate(\n",
        "                input_ids=passage_ids,\n",
        "                attention_mask=passage_masks,\n",
        "                max_length=10,\n",
        "                early_stopping=True,\n",
        "                num_beams=3,\n",
        "                top_k=1\n",
        "            )"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dovSpbkS6fAz",
        "outputId": "3cb4c879-d3ab-43f8-ce34-2327e4405e21"
      },
      "source": [
        "for k, o in enumerate(outputs):\n",
        "  ans = tokenizer.decode(o, skip_special_tokens=True)\n",
        "  print(ans)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Narendra Modi PM of India Narendra\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}